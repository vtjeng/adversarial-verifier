using MAT
using JuMP
using Gurobi
include("nn_ops.jl")
include("util.jl")

"""
Warning for adding constraints: zero or small (< 1e-13) coefficients, ignored
Optimize a model with 7004 rows, 4710 columns and 57612 nonzeros
Model has 196 quadratic objective terms
Variable types: 2882 continuous, 1828 integer (1828 binary)
Coefficient statistics:
  Matrix range     [2e-07, 3e+01]
  Objective range  [0e+00, 0e+00]
  QObjective range [2e+00, 2e+00]
  Bounds range     [1e+00, 1e+00]
  RHS range        [1e-04, 3e+01]
Presolve removed 2202 rows and 1101 columns
Presolve time: 0.56s
Presolved: 4802 rows, 3609 columns, 56151 nonzeros
Presolved model has 196 quadratic objective terms

Loaded MIP start with objective 0.503175

Variable types: 2229 continuous, 1380 integer (1380 binary)
Presolve removed 596 rows and 596 columns
Presolved: 4206 rows, 3013 columns, 54363 nonzeros
Presolved model has 196 quadratic objective terms


Root simplex log...

Iteration    Objective       Primal Inf.    Dual Inf.      Time
   31441    6.8360059e-02   1.777114e+02   0.000000e+00      5s
   49846    0.0000000e+00   0.000000e+00   0.000000e+00      9s
   49846    0.0000000e+00   0.000000e+00   0.000000e+00      9s

Root relaxation: objective 0.000000e+00, 49846 iterations, 8.32 seconds

    Nodes    |    Current Node    |     Objective Bounds      |     Work
 Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time

     0     0    0.00000    0  730    0.50317    0.00000   100%     -    9s
     0     0    0.00000    0  660    0.50317    0.00000   100%     -   31s
     0     0    0.00000    0  655    0.50317    0.00000   100%     -   31s
     0     0    0.00000    0  637    0.50317    0.00000   100%     -   54s
     0     0    0.00000    0  636    0.50317    0.00000   100%     -   55s
     0     0    0.00000    0  725    0.50317    0.00000   100%     -   85s
     0     0    0.00000    0  643    0.50317    0.00000   100%     -  201s
     0     0    0.00000    0  682    0.50317    0.00000   100%     -  226s
     0     0    0.00000    0  602    0.50317    0.00000   100%     -  230s
     0     0    0.00000    0  693    0.50317    0.00000   100%     -  748s
     0     0    0.00000    0  650    0.50317    0.00000   100%     -  770s
     0     0    0.00000    0  650    0.50317    0.00000   100%     -  770s
     0     2    0.00000    0  650    0.50317    0.00000   100%     -  776s
     4     4    0.46940    2  621    0.50317    0.00000   100%  46.0  806s
     7     6    0.46940    3  621    0.50317    0.00000   100%  9770  881s
    12     9    0.47804    4  640    0.50317    0.00000   100% 45730  897s
    18    13    0.00000    6  615    0.50317    0.00000   100% 30512  900s
    30    22    0.47804    7  650    0.50317    0.00000   100% 18324  928s
    32    23    0.31657    6  750    0.50317    0.00000   100% 17179  935s
    33    24    0.46940    9  739    0.50317    0.00000   100% 16658 1194s
    34    25    0.47804    9  745    0.50317    0.00000   100% 16168 1429s
    35    25    0.12227    9  721    0.50317    0.00000   100% 15706 1673s
    36    26    0.14923    8  694    0.50317    0.00000   100% 15270 1690s
    37    27    0.46940    9  712    0.50317    0.00000   100% 14857 1874s
    38    27    0.39192    4  676    0.50317    0.00000   100% 14466 1878s
    39    28    0.47804    9  705    0.50317    0.00000   100% 14095 2159s
    40    29    0.46940    8  699    0.50317    0.00000   100% 13743 2410s
    41    29    0.46940    9  692    0.50317    0.00000   100% 13408 2578s
    42    30    0.46940    9  679    0.50317    0.00000   100% 13089 2850s
    43    31    0.39192    4  682    0.50317    0.00000   100% 12784 3042s
    44    31    0.46940    9  673    0.50317    0.00000   100% 12494 3255s
    45    32    0.14923    8  684    0.50317    0.00000   100% 12216 3312s
    46    33    0.46940    9  692    0.50317    0.00000   100% 11950 3554s
    47    33    0.47804    9  578    0.50317    0.00000   100% 11696 4058s
    48    34    0.14923    8  664    0.50317    0.00000   100% 11453 4256s
    49    35    0.00000    9  652    0.50317    0.00000   100% 11219 4500s
    50    35    0.47804    7  650    0.50317    0.00000   100% 10994 4630s
    51    36    0.47804    9  719    0.50317    0.00000   100% 10779 4922s
    55    39    0.12227    9  703    0.50317    0.00000   100%  9995 4930s
    57    40    0.46940    9  650    0.50317    0.00000   100% 233436 5099s
    59    41    0.47804    9  750    0.50317    0.00000   100% 225523 5195s
    60    42    0.46940    8  666    0.50317    0.00000   100% 221764 5339s
    61    43    0.46940    9  635    0.50317    0.00000   100% 218129 5678s
    62    43    0.46940    9  667    0.50317    0.00000   100% 214611 5901s
    63    44    0.39192    4  662    0.50317    0.00000   100% 211204 6209s
    64    45    0.46940    9  666    0.50317    0.00000   100% 207904 6571s
    65    45    0.14923    8  671    0.50317    0.00000   100% 204706 6932s
    66    46    0.46940    9  655    0.50317    0.00000   100% 201604 7188s
    67    47    0.47804    9  686    0.50317    0.00000   100% 198595 7537s
    68    47    0.14923    8  678    0.50317    0.00000   100% 195674 7778s
    69    48    0.00000    9  681    0.50317    0.00000   100% 192839 8035s
    70    49    0.47804    7  662    0.50317    0.00000   100% 190084 8189s
    73    51    0.46940    9  640    0.50317    0.00000   100% 182272 8197s
    75    52    0.12227    9  650    0.50317    0.00000   100% 318036 8479s
    77    53    0.46940    9  697    0.50317    0.00000   100% 309775 9030s
    78    54    0.39192    4  676    0.50317    0.00000   100% 305803 9321s
    79    55    0.47804    9  643    0.50317    0.00000   100% 301932 9387s
    80    55    0.46940    8  670    0.50317    0.00000   100% 298158 9759s
    81    56    0.46940    9  621    0.50317    0.00000   100% 294477 9809s
    82    57    0.46940    9  652    0.50317    0.00000   100% 290886 10234s
    83    57    0.39192    4  667    0.50317    0.00000   100% 287381 10514s
    84    58    0.46940    9  617    0.50317    0.00000   100% 283960 10660s
    85    59    0.14923    8  643    0.50317    0.00000   100% 280620 11064s
    86    59    0.46940    9  622    0.50317    0.00000   100% 277357 11370s
    87    60    0.47804    9  626    0.50317    0.00000   100% 274169 11645s
    88    61    0.14923    8  688    0.50317    0.00000   100% 271053 11876s
    89    61    0.00000    9  657    0.50317    0.00000   100% 268007 12235s
    90    62    0.47804    7  590    0.50317    0.00000   100% 265030 13250s
    91    63    0.47804    9  638    0.50317    0.00000   100% 262117 13503s
    92    63    0.31657    6  630    0.50317    0.00000   100% 259268 13580s
    93    64    0.46940    9  628    0.50317    0.00000   100% 256480 13700s
    94    65    0.47804    9  654    0.50317    0.00000   100% 253752 13833s
    97    67    0.46940    9  650    0.50317    0.00000   100% 245904 13841s
    99    69    0.47804    9  650    0.50317    0.00000   100% 420893 14335s
   101    70    0.46940    9  704    0.50317    0.00000   100% 412559 14341s
   102    71    0.46940    9  655    0.50317    0.00000   100% 408514 14420s
   103    72    0.39192    4  638    0.50317    0.00000   100% 404548 14530s
   104    72    0.46940    9  625    0.50317    0.00000   100% 400658 14842s
   105    73    0.14923    8  634    0.50317    0.00000   100% 396842 15188s
   106    74    0.46940    9  627    0.50317    0.00000   100% 393098 15317s
   107    74    0.47804    9  638    0.50317    0.00000   100% 389425 15535s
   108    75    0.14923    8  654    0.50317    0.00000   100% 385819 15554s
   109    76    0.00000    9  664    0.50317    0.00000   100% 382279 15855s
   110    76    0.47804    7  647    0.50317    0.00000   100% 378804 16033s
   111    77    0.47804    9  635    0.50317    0.00000   100% 375391 16253s
   112    78    0.31657    6  668    0.50317    0.00000   100% 372040 16676s
   115    80    0.12227    9  663    0.50317    0.00000   100% 362334 16683s
   117    82    0.46940    9  650    0.50317    0.00000   100% 428514 17244s
   119    83    0.47804    9  699    0.50317    0.00000   100% 421312 17249s
   120    84    0.46940    8  631    0.50317    0.00000   100% 417801 17371s
   121    85    0.46940    9  661    0.50317    0.00000   100% 414348 17594s
   122    85    0.46940    9  644    0.50317    0.00000   100% 410952 17872s
   123    86    0.39192    4  641    0.50317    0.00000   100% 407611 18218s
   124    87    0.46940    9  615    0.50317    0.00000   100% 404323 18533s
   125    87    0.14923    8  637    0.50317    0.00000   100% 401089 18711s
   126    88    0.46940    9  614    0.50317    0.00000   100% 397906 19002s
   127    89    0.47804    9  628    0.50317    0.00000   100% 394772 19153s
   128    89    0.14923    8  655    0.50317    0.00000   100% 391688 19306s
   129    90    0.00000    9  653    0.50317    0.00000   100% 388652 19465s
   130    91    0.47804    7  674    0.50317    0.00000   100% 385662 19513s
   131    91    0.47804    9  619    0.50317    0.00000   100% 382718 19694s
   132    92    0.31657    6  617    0.50317    0.00000   100% 379819 19862s
   135    94    0.12227    9  615    0.50317    0.00000   100% 371379 19870s
   137    97    0.46940    9  650    0.50317    0.00000   100% 430061 20532s
   139    98    0.47804    9  681    0.50317    0.00000   100% 423874 20547s
   140    99    0.46940    8  677    0.50317    0.00000   100% 420846 20798s
   141   100    0.46940    9  607    0.50317    0.00000   100% 417861 20930s
   142   100    0.46940    9  561    0.50317    0.00000   100% 414918 21638s
   143   101    0.39192    4  614    0.50317    0.00000   100% 412017 21856s
   144   102    0.46940    9  619    0.50317    0.00000   100% 409156 22205s
   145   102    0.14923    8  659    0.50317    0.00000   100% 406334 22450s
   146   103    0.46940    9  638    0.50317    0.00000   100% 403551 22678s
   147   104    0.47804    9  609    0.50317    0.00000   100% 400806 22952s
   148   104    0.14923    8  676    0.50317    0.00000   100% 398097 23215s
   149   105    0.00000    9  626    0.50317    0.00000   100% 395426 23538s
   150   106    0.47804    7  618    0.50317    0.00000   100% 392789 23877s
   152   107    0.31657    6  618    0.50317    0.00000   100% 387621 23885s
   154   110    0.47804    9  650    0.50317    0.00000   100% 454675 24725s
   156   111    0.14923    8  655    0.50317    0.00000   100% 448846 24753s
   157   112    0.46940    9  654    0.50317    0.00000   100% 445987 25028s
   158   113    0.39192    4  602    0.50317    0.00000   100% 443164 25193s
   159   113    0.47804    9  619    0.50317    0.00000   100% 440377 25404s
   160   114    0.46940    8  636    0.50317    0.00000   100% 437625 25559s
   161   115    0.46940    9  644    0.50317    0.00000   100% 434906 25796s
   162   115    0.46940    9  617    0.50317    0.00000   100% 432222 26276s
   163   116    0.39192    4  613    0.50317    0.00000   100% 429570 26497s
   164   117    0.46940    9  650    0.50317    0.00000   100% 426951 26704s
   165   117    0.14923    8  627    0.50317    0.00000   100% 424363 27238s
   166   118    0.46940    9  623    0.50317    0.00000   100% 421807 27328s
   167   119    0.47804    9  580    0.50317    0.00000   100% 419281 27673s
   168   119    0.14923    8  575    0.50317    0.00000   100% 416785 28441s
   169   120    0.00000    9  632    0.50317    0.00000   100% 414319 28779s
   170   121    0.47804    7  598    0.50317    0.00000   100% 411882 28797s
   171   121    0.47804    9  631    0.50317    0.00000   100% 409473 29080s
   172   122    0.31657    6  622    0.50317    0.00000   100% 407093 29386s
   175   124    0.12227    9  620    0.50317    0.00000   100% 400114 29393s
   177   127    0.46940    9  650    0.50317    0.00000   100% 484232 30384s
   179   128    0.47804    9  663    0.50317    0.00000   100% 478821 30389s
   180   129    0.46940    8  625    0.50317    0.00000   100% 476161 30662s
   181   130    0.46940    9  620    0.50317    0.00000   100% 473530 30929s
   182   130    0.46940    9  625    0.50317    0.00000   100% 470929 31195s
   183   131    0.39192    4  593    0.50317    0.00000   100% 468355 31506s
   184   132    0.46940    9  666    0.50317    0.00000   100% 465810 31655s
   186   133    0.46940    9  666    0.50317    0.00000   100% 460801 31664s
   188   136    0.14923    8  650    0.50317    0.00000   100% 478296 32762s
   190   137    0.47804    7  670    0.50317    0.00000   100% 473261 32768s
   191   138    0.47804    9  572    0.50317    0.00000   100% 470783 32999s
   192   139    0.31657    6  646    0.50317    0.00000   100% 468331 33582s
   193   139    0.46940    9  617    0.50317    0.00000   100% 465905 33784s
   194   140    0.47804    9  616    0.50317    0.00000   100% 463503 33831s
   195   141    0.12227    9  647    0.50317    0.00000   100% 461126 33982s
   198   143    0.39192    4  645    0.50317    0.00000   100% 454140 33990s
   200   145    0.46940    8  650    0.50317    0.00000   100% 472074 35152s
   202   146    0.46940    9  644    0.50317    0.00000   100% 467400 35156s
   203   147    0.39192    4  655    0.50317    0.00000   100% 465098 35335s
   204   148    0.46940    9  607    0.50317    0.00000   100% 462818 35421s
   205   148    0.14923    8  609    0.50317    0.00000   100% 460560 35527s
   206   149    0.46940    9  644    0.50317    0.00000   100% 458325 35579s
   207   150    0.47804    9  649    0.50317    0.00000   100% 456110 35927s
   208   150    0.14923    8  645    0.50317    0.00000   100% 453918 36295s
   209   151    0.00000    9  620    0.50317    0.00000   100% 451746 36551s
   210   152    0.47804    7  611    0.50317    0.00000   100% 449595 36989s
   211   152    0.47804    9  653    0.50317    0.00000   100% 447464 37131s
   212   153    0.31657    6  642    0.50317    0.00000   100% 445353 37480s
   213   154    0.46940    9  629    0.50317    0.00000   100% 443262 37568s
   215   155    0.12227    9  629    0.50317    0.00000   100% 439139 37575s
   216   159    0.00000  111  629    0.50317    0.00000   100% 474973 37649s
   218   159    0.00000  112  628    0.50317    0.00000   100% 472120 37696s
   222   160    0.00000  113  626    0.50317    0.00000   100% 463917 37781s
   226   160    0.00000  114  625    0.50317    0.00000   100% 459855 37865s
   230   163    0.00000  115  624    0.50317    0.00000   100% 453859 37963s
   234   165    0.00000  116  623    0.50317    0.00000   100% 450545 38048s
   238   165    0.00000  117  622    0.50317    0.00000   100% 446000 38133s
   243   169    0.00000  119  611    0.50317    0.00000   100% 438700 38222s
   248   168    0.00000  120  611    0.50317    0.00000   100% 433824 38307s
   253   171    0.00000  121  611    0.50317    0.00000   100% 427060 38393s
   258   169    0.45854  122  602    0.50317    0.00000   100% 421625 38479s
   266   172    0.00000  125  607    0.50317    0.00000   100% 411648 38564s
   272   179    0.00000  128  610    0.50317    0.00000   100% 405249 38647s
   280   179    0.00000  131  596    0.50317    0.00000   100% 396014 38732s
   290   188    0.00000  135  592    0.50317    0.00000   100% 384620 38817s
   300   193    0.00000  139  582    0.50317    0.00000   100% 373986 38906s
   309   200    0.00000  142  582    0.50317    0.00000   100% 366278 38994s
   317   198    0.00000  146  577    0.50317    0.00000   100% 360139 39092s
   322   208  postponed  147         0.50317    0.00000   100% 359638 39191s
   326   206    0.00000  148  549    0.50317    0.00000   100% 358416 39299s
   333   215    0.00000  150  543    0.50317    0.00000   100% 354821 39388s
   342   213    0.00000  154  538    0.50317    0.00000   100% 348361 39485s
   348   220    0.00000  155  536    0.50317    0.00000   100% 345999 39574s
   361   221    0.00000  157  535    0.50317    0.00000   100% 336265 39662s
   377   236    0.00000  161  537    0.50317    0.00000   100% 324604 39760s
   382   234    0.00000  162  536    0.50317    0.00000   100% 323789 39870s
   388   241    0.00000  163  536    0.50317    0.00000   100% 322313 39977s
   401   243    0.00000  168  532    0.50317    0.00000   100% 315283 40082s
   409   242    0.00000  170  530    0.50317    0.00000   100% 312469 40166s
   431   253    0.00914  176  523    0.50317    0.00000   100% 298136 40247s
   455   272    0.00000  183  520    0.50317    0.00000   100% 283853 40351s
   473   274    0.00000  186  513    0.50317    0.00000   100% 275824 40452s
   481   277    0.00000  188  512    0.50317    0.00000   100% 273964 40584s
   499   287    0.00000  196  510    0.50317    0.00000   100% 266711 40674s
   518   302    0.44033  203  509    0.50317    0.00000   100% 258837 40762s
   537   308    0.00000  212  490    0.50317    0.00000   100% 251512 40851s
   557   322    0.00000  221  483    0.50317    0.00000   100% 244247 40940s
   578   334    0.00376  230  479    0.50317    0.00000   100% 237076 41028s
   602   350    0.05002  240  475    0.50317    0.00000   100% 229260 41123s
   626   361    0.00000  251  460    0.50317    0.00000   100% 222139 41218s
   651   383    0.04489  261  466    0.50317    0.00000   100% 215217 41323s
   664   388  postponed  266         0.50317    0.00000   100% 213569 41494s
   670   390  postponed  266         0.50317    0.00000   100% 214199 41686s
   678   399  postponed  267         0.50317    0.00000   100% 215540 41883s
   686   404  postponed  268         0.50317    0.00000   100% 216850 42076s
   694   410  postponed  269         0.50317    0.00000   100% 218130 42272s
   702   412  postponed  270         0.50317    0.00000   100% 219381 42463s
   712   420  postponed  271         0.50317    0.00000   100% 219889 42667s
   742   446  postponed  273         0.50317    0.00000   100% 214332 42856s
   775   481  postponed  274         0.50317    0.00000   100% 207944 43034s
   821   521  postponed  275         0.50317    0.00000   100% 198689 43341s
   898   595  postponed  276         0.50317    0.00000   100% 185372 43664s
   978   678    0.04756  278  524    0.50317    0.00000   100% 173741 44002s
  1065   761  postponed  281         0.50317    0.00000   100% 163358 44374s
  1154   851  postponed  283         0.50317    0.00000   100% 154838 44782s
  1171   868  postponed  285         0.50317    0.00000   100% 156769 45216s
  1187   883  postponed  287         0.50317    0.00000   100% 159076 45648s
  1203   893  postponed  289         0.50317    0.00000   100% 161321 46080s
  1220   915  postponed  291         0.50317    0.00000   100% 163416 46509s
  1236   929  postponed  293         0.50317    0.00000   100% 165545 46937s
  1254   946  postponed  295         0.50317    0.00000   100% 167353 47425s
  1273   963  postponed  297         0.50317    0.00000   100% 169749 47915s
  1294   972  postponed  300         0.50317    0.00000   100% 171846 48408s
  1318   996  postponed  302         0.50317    0.00000   100% 173493 48943s
  1341  1009  postponed  305         0.50317    0.00000   100% 175408 49476s
  1366  1024  postponed  307         0.50317    0.00000   100% 177000 50011s
  1391  1038  postponed  310         0.50317    0.00000   100% 178534 50593s
  1422  1057  postponed  313         0.50317    0.00000   100% 179988 51173s
  1452  1072  postponed  316         0.50317    0.00000   100% 181465 51771s
  1540  1143  postponed  319         0.50317    0.00000   100% 176116 52421s
  1569  1167  postponed  322         0.50317    0.00000   100% 178652 53068s
  1690  1288  postponed  325         0.50317    0.00000   100% 170435 53699s
  1819  1419  postponed  328         0.50317    0.00000   100% 162379 54388s
  1951  1544  postponed  332         0.50317    0.00000   100% 155912 55065s
  1995  1588  postponed  335         0.50317    0.00000   100% 157057 55771s
  2078  1669  postponed  340         0.50317    0.00000   100% 155204 56546s
  2135  1717  postponed  344         0.50317    0.00000   100% 155575 57537s
  2205  1784  postponed  348         0.50317    0.00000   100% 155454 58694s
  2259  1840  postponed  352         0.50317    0.00000   100% 156500 60090s
"""

### Parameters for neural net
batch = 1
in1_height = 14
in1_width = 14
stride1_height = 2
stride1_width = 2
pooled1_height = round(Int, in1_height/stride1_height, RoundUp)
pooled1_width = round(Int, in1_width/stride1_width, RoundUp)
in1_channels = 1
filter1_height = 3
filter1_width = 3
out1_channels = 4

in2_height = pooled1_height
in2_width = pooled1_width
stride2_height = 1
stride2_width = 1
pooled2_height = round(Int, in2_height/stride2_height, RoundUp)
pooled2_width = round(Int, in2_width/stride2_width, RoundUp)
in2_channels = out1_channels
filter2_height = 3
filter2_width = 3
out2_channels = 8

bigM = 10000

A_height = 64
A_width = pooled2_height*pooled2_width*out2_channels

B_height = 10
B_width = A_height

UUID = "2017-09-28_181157"
nn_params = matread("data/$UUID-ch-params.mat")
x_adv = matread("data/$UUID-adversarial-examples.mat")["adv_x"]
mnist_test_data_resized = matread("data/mnist_test_data_resized.mat")
test_index = 2 # which test sample we're choosing
y_ = mnist_test_data_resized["y_"]
x_resize = mnist_test_data_resized["x_resize"]
actual_label = get_label(y_, test_index)
x0 = get_input(x_resize, test_index) # NB: weird indexing preserves singleton first dimension

filter1 = nn_params["conv1/weight"]
bias1 = squeeze(nn_params["conv1/bias"], 1)
filter2 = nn_params["conv2/weight"]
bias2 = squeeze(nn_params["conv2/bias"], 1)
A = transpose(nn_params["fc1/weight"])
biasA = squeeze(nn_params["fc1/bias"], 1)
B = transpose(nn_params["logits/weight"])
biasB = squeeze(nn_params["logits/bias"], 1)

check_size(x0, (batch, in1_height, in1_width, in1_channels))
check_size(filter1, (filter1_height, filter1_width, in1_channels, out1_channels))
check_size(bias1, (out1_channels, ))
check_size(filter2, (filter2_height, filter2_width, in2_channels, out2_channels))
check_size(bias2, (out2_channels, ))
check_size(A, (A_height, A_width))
check_size(biasA, (A_height, ))
check_size(B, (B_height, B_width))
check_size(biasB, (B_height, ))

function calculate_predicted_label{T<:Real}(
    x0_::AbstractArray{T, 4})::Int
    x1_ = NNOps.convlayer(x0_, filter1, bias1, (stride1_height, stride1_width))
    x2_ = NNOps.convlayer(x1_, filter2, bias2, (stride2_height, stride2_width))
    x3_ = NNOps.flatten(x2_)
    x4_ = NNOps.fullyconnectedlayer(x3_, A, biasA)
    predicted_label = NNOps.softmaxindex(x4_, B, biasB)
    return predicted_label
end

num_samples = 100
num_correct = 0

target_label = -1 # TODO: fix
min_dist = Inf
target_sample_index = -1 # TODO: fix

test_predicted_label = calculate_predicted_label(x0)
adversarial_image = NNOps.avgpool(get_input(x_adv, test_index), (1, 2, 2, 1))
adversarial_predicted_label = calculate_predicted_label(adversarial_image)
println("FGSM adversarial image predicted label by NN is $adversarial_predicted_label, original image predicted label by NN is $test_predicted_label.")
for i = 1:num_samples
    sample_image = get_input(x_resize, i)
    sample_predicted_label = calculate_predicted_label(sample_image)
    sample_actual_label = get_label(y_, i)
    # println("Running test case $i. Predicted is $pred, actual is $actual.")
    if sample_predicted_label == sample_actual_label
        num_correct += 1
    end
    sample_dist = sum((sample_image-x0).^2)
    if (sample_predicted_label != test_predicted_label) && (sample_dist < min_dist)
        target_label = sample_predicted_label
        min_dist = sample_dist
        target_sample_index = i
        println("New minimum distance, $min_dist at target sample index $target_sample_index.")
    end
end
candidate_adversarial_example = get_input(x_resize, target_sample_index)

adversarial_dist = sum((adversarial_image-x0).^2)
if (adversarial_predicted_label!=test_predicted_label) && (adversarial_dist < min_dist)
    target_label = adversarial_predicted_label
    min_dist = adversarial_dist
    candidate_adversarial_example = adversarial_image
    println("Using adversarial example at new minimum distance, $adversarial_dist.")
end
println("Number correct on regular samples is $num_correct out of $num_samples.")

## Calculate intermediate values
x1 = NNOps.convlayer(x0, filter1, bias1, (stride1_height, stride1_width))
x2 = NNOps.convlayer(x1, filter2, bias2, (stride2_height, stride2_width))
x3 = NNOps.flatten(x2)
x4 = NNOps.fullyconnectedlayer(x3, A, biasA)
predicted_label = NNOps.softmaxindex(x4, B, biasB)

m = Model(solver=GurobiSolver(MIPFocus = 3))

@variable(m, ve[1:batch, 1:in1_height, 1:in1_width, 1:in1_channels])
@variable(m, 0 <= vx0[1:batch, 1:in1_height, 1:in1_width, 1:in1_channels] <= 1)
@constraint(m, vx0 .== x0 + ve) # input

vx1 = NNOps.convlayerconstraint(m, vx0, filter1, bias1, (stride1_height, stride1_width), 10)
vx2 = NNOps.convlayerconstraint(m, vx1, filter2, bias2, (stride2_height, stride2_width), 10)
vx3 = NNOps.flatten(vx2)
vx4 = NNOps.fullyconnectedlayerconstraint(m, vx3, A, biasA, 30)

setvalue(ve, candidate_adversarial_example - x0)
NNOps.softmaxconstraint(m, vx4, B, biasB, target_label)

@objective(m, Min, sum(ve.^2))

println("Attempting to prove optimality of candidate adversarial example. Neural net predicted label is $predicted_label, target label is $target_label")

solve(m)

println("Objective value: ", getobjectivevalue(m))
println("e = ", getvalue(ve))
